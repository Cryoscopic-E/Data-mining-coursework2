
loss=hinge. penalty=l2, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.83      0.94      0.88      1451
           1       0.88      0.94      0.91      1953
           2       0.98      0.87      0.92       445
           3       0.99      0.93      0.96      1346
           4       0.94      0.93      0.94      2185
           5       0.96      0.95      0.96      2273
           6       0.99      0.94      0.96       830
           7       0.78      0.79      0.79       229
           8       0.97      0.93      0.95      2156
           9       0.99      0.96      0.97       302

    accuracy                           0.93     13170
   macro avg       0.93      0.92      0.92     13170
weighted avg       0.94      0.93      0.93     13170

CONFUSION MATRIX ----------------------
[[1358   78    1    0    1   10    2    0    1    0]
 [  92 1834    0    2    9    7    1    2    5    1]
 [   7   26  387    0    5    0    0   15    5    0]
 [  24   19    0 1256   30    3    0    7    5    2]
 [  38   59    0    5 2038   15    0   13   17    0]
 [  30   36    5    2   26 2156    4    8    6    0]
 [  21    9    0    0    2    0  781    0   17    0]
 [   7   16    1    0   21    2    0  182    0    0]
 [  59   18    0    0   27   45    2    7 1997    1]
 [   7    1    0    0    3    0    0    0    1  290]]
ACCURACY ----------------------
0.9323462414578587
================================================

loss=hinge. penalty=l2, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.83      0.95      0.89      1451
           1       0.92      0.89      0.91      1953
           2       0.97      0.87      0.92       445
           3       0.99      0.94      0.96      1346
           4       0.92      0.95      0.93      2185
           5       0.99      0.93      0.96      2273
           6       1.00      0.93      0.96       830
           7       0.88      0.70      0.78       229
           8       0.91      0.97      0.94      2156
           9       0.99      0.97      0.98       302

    accuracy                           0.93     13170
   macro avg       0.94      0.91      0.92     13170
weighted avg       0.94      0.93      0.93     13170

CONFUSION MATRIX ----------------------
[[1373   51    2    3    6    3    0    0   13    0]
 [ 128 1747    0    7   36    3    0    0   31    1]
 [  15    9  387    0   10    0    0   10   14    0]
 [   7    8    1 1265   39    3    0    2   20    1]
 [  26   28    0    2 2075    7    0    5   42    0]
 [  27   24    7    5   36 2125    3    4   40    2]
 [  24   10    0    1    7    0  768    0   20    0]
 [  10    7    2    0   32    2    0  161   15    0]
 [  36    9    0    0   11    2    0    2 2096    0]
 [   5    1    0    0    2    0    0    0    1  293]]
ACCURACY ----------------------
0.9331814730447988
================================================

loss=hinge. penalty=elasticnet, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.88      0.90      0.89      1451
           1       0.85      0.97      0.91      1953
           2       0.96      0.88      0.92       445
           3       0.98      0.95      0.97      1346
           4       0.96      0.94      0.95      2185
           5       0.99      0.93      0.96      2273
           6       0.98      0.94      0.96       830
           7       0.73      0.81      0.77       229
           8       0.96      0.95      0.96      2156
           9       1.00      0.96      0.98       302

    accuracy                           0.94     13170
   macro avg       0.93      0.92      0.92     13170
weighted avg       0.94      0.94      0.94     13170

CONFUSION MATRIX ----------------------
[[1302  131    2    3    2    1    2    0    8    0]
 [  29 1894    0    6    8    3    1    2   10    0]
 [   3   22  390    0    4    0    0   12   14    0]
 [   6   16    1 1275   29    0    0   10    8    1]
 [  17   68    1    9 2044    5    3   18   20    0]
 [  28   55   10    2   19 2119    4   21   15    0]
 [  26    8    0    0    1    0  779    1   15    0]
 [   8   14    1    0   20    1    0  185    0    0]
 [  60   19    0    1   10    1    3    5 2057    0]
 [   7    5    0    0    0    0    0    0    1  289]]
ACCURACY ----------------------
0.9365223993925589
================================================

loss=hinge. penalty=elasticnet, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.86      0.91      0.88      1451
           1       0.89      0.94      0.92      1953
           2       0.98      0.89      0.93       445
           3       0.94      0.96      0.95      1346
           4       0.93      0.95      0.94      2185
           5       0.99      0.94      0.97      2273
           6       1.00      0.87      0.93       830
           7       0.82      0.75      0.78       229
           8       0.96      0.96      0.96      2156
           9       0.95      0.97      0.96       302

    accuracy                           0.94     13170
   macro avg       0.93      0.91      0.92     13170
weighted avg       0.94      0.94      0.94     13170

CONFUSION MATRIX ----------------------
[[1324   94    1   14    3    5    0    2    8    0]
 [  48 1832    0   23   30    3    0    2   12    3]
 [   6   15  394    0    9    0    0   10   11    0]
 [   4    6    0 1290   33    0    0    6    5    2]
 [  15   37    2   21 2074    7    0    8   15    6]
 [  33   30    4   10   28 2144    0    6   14    4]
 [  52   17    0    7    8    0  721    1   24    0]
 [   9   12    1    2   32    2    0  171    0    0]
 [  46    6    0    4   11    6    0    3 2079    1]
 [   5    2    0    0    0    0    0    0    1  294]]
ACCURACY ----------------------
0.9356871678056188
================================================

loss=perceptron. penalty=l2, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.84      0.94      0.88      1451
           1       0.89      0.95      0.92      1953
           2       0.92      0.89      0.90       445
           3       0.92      0.97      0.95      1346
           4       0.95      0.91      0.93      2185
           5       0.95      0.95      0.95      2273
           6       0.99      0.97      0.98       830
           7       0.83      0.74      0.78       229
           8       0.99      0.90      0.94      2156
           9       0.99      0.97      0.98       302

    accuracy                           0.93     13170
   macro avg       0.93      0.92      0.92     13170
weighted avg       0.93      0.93      0.93     13170

CONFUSION MATRIX ----------------------
[[1360   62    4   12    1    9    2    0    1    0]
 [  69 1846    0   19    6    8    1    1    3    0]
 [   4   32  394    0    2    0    0   11    2    0]
 [   4   10    1 1301   17    7    1    2    1    2]
 [  42   62    5   46 1999   23    0    7    1    0]
 [  33   33   11   12   11 2160    5    4    3    1]
 [  16    4    0    5    1    0  802    0    2    0]
 [  16    3    4    3   32    2    0  169    0    0]
 [  74   15    7    9   28   68    3    9 1942    1]
 [   6    2    1    0    0    0    0    0    1  292]]
ACCURACY ----------------------
0.931283219438117
================================================

loss=perceptron. penalty=l2, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.87      0.92      0.89      1451
           1       0.86      0.96      0.91      1953
           2       0.97      0.85      0.91       445
           3       0.96      0.95      0.95      1346
           4       0.93      0.95      0.94      2185
           5       0.99      0.94      0.96      2273
           6       0.97      0.95      0.96       830
           7       0.81      0.75      0.78       229
           8       0.98      0.94      0.96      2156
           9       1.00      0.93      0.96       302

    accuracy                           0.94     13170
   macro avg       0.93      0.91      0.92     13170
weighted avg       0.94      0.94      0.94     13170

CONFUSION MATRIX ----------------------
[[1331  105    0    7    2    1    2    2    1    0]
 [  40 1875    0   14   12    3    1    2    6    0]
 [   6   38  380    0    5    0    0   11    5    0]
 [   6   16    0 1272   38    0    4    6    4    0]
 [  19   52    1   14 2073    5    2    9   10    0]
 [  31   39    9    8   36 2127    6    6   10    1]
 [  22   11    0    0    1    0  791    1    4    0]
 [   6   13    1    1   35    2    0  171    0    0]
 [  68   14    0    2   28    5    5    4 2030    0]
 [   6   11    0    1    2    0    1    0    0  281]]
ACCURACY ----------------------
0.936294608959757
================================================

loss=perceptron. penalty=elasticnet, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.83      0.91      0.87      1451
           1       0.87      0.96      0.91      1953
           2       0.99      0.82      0.89       445
           3       0.92      0.97      0.94      1346
           4       0.94      0.94      0.94      2185
           5       0.97      0.95      0.96      2273
           6       0.99      0.94      0.96       830
           7       0.87      0.70      0.78       229
           8       0.99      0.91      0.95      2156
           9       0.98      0.97      0.97       302

    accuracy                           0.93     13170
   macro avg       0.93      0.91      0.92     13170
weighted avg       0.93      0.93      0.93     13170

CONFUSION MATRIX ----------------------
[[1324  102    0   17    1    5    2    0    0    0]
 [  37 1876    0   21    5    6    1    1    3    3]
 [  11   47  363    1    8    0    0   12    3    0]
 [   5    9    0 1299   29    2    0    1    1    0]
 [  26   60    0   32 2049   10    0    4    4    0]
 [  41   32    3   19   20 2149    2    2    4    1]
 [  29    6    0    8    1    0  782    0    4    0]
 [  15    7    1    3   40    2    0  161    0    0]
 [ 100    9    0   16   28   34    4    5 1959    1]
 [   6    3    0    0    0    0    0    0    1  292]]
ACCURACY ----------------------
0.9304479878511769
================================================

loss=perceptron. penalty=elasticnet, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.81      0.95      0.87      1451
           1       0.88      0.95      0.91      1953
           2       0.98      0.85      0.91       445
           3       0.97      0.96      0.97      1346
           4       0.96      0.92      0.94      2185
           5       0.97      0.94      0.96      2273
           6       1.00      0.90      0.95       830
           7       0.81      0.76      0.79       229
           8       0.97      0.94      0.96      2156
           9       1.00      0.95      0.97       302

    accuracy                           0.93     13170
   macro avg       0.94      0.91      0.92     13170
weighted avg       0.94      0.93      0.94     13170

CONFUSION MATRIX ----------------------
[[1381   57    1    3    2    6    0    0    1    0]
 [  67 1862    0    9    3    5    0    2    5    0]
 [   8   38  380    0    5    0    0   10    4    0]
 [  12   12    0 1290   23    3    0    4    2    0]
 [  49   68    0   16 2011   14    0    9   18    0]
 [  40   43    5    6   15 2147    0    8    9    0]
 [  51   17    0    1    1    1  745    1   13    0]
 [  19    3    0    1   30    2    0  174    0    0]
 [  70   16    0    0    5   26    0    6 2033    0]
 [   9    5    0    0    0    0    0    0    1  287]]
ACCURACY ----------------------
0.9347000759301443
================================================

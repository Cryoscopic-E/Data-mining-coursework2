
loss=hinge. penalty=l2, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.91      0.93      0.92       900
           1       0.90      0.94      0.92      1217
           2       1.00      0.82      0.90       298
           3       0.98      0.95      0.96       839
           4       0.93      0.95      0.94      1340
           5       0.97      0.95      0.96      1425
           6       0.99      0.92      0.96       511
           7       0.55      0.83      0.66       121
           8       0.96      0.95      0.96      1327
           9       0.98      0.95      0.97       192

    accuracy                           0.94      8170
   macro avg       0.92      0.92      0.91      8170
weighted avg       0.94      0.94      0.94      8170

CONFUSION MATRIX ----------------------
[[ 833   47    1    3    8    3    1    0    4    0]
 [  25 1144    0    2   26    5    0    0   13    2]
 [   3   23  243    0    6    0    0   19    4    0]
 [   2    9    0  794   11    2    1   15    4    1]
 [   2   26    0    5 1268   11    0   19    8    1]
 [  19   17    0    1   13 1356    1    9    9    0]
 [  15    3    0    1    9    0  471    0   12    0]
 [   3    1    0    0   17    0    0  100    0    0]
 [  14    3    0    1    9   15    0   20 1265    0]
 [   4    1    0    0    3    0    0    0    1  183]]
ACCURACY ----------------------
0.9372093023255814
================================================

loss=hinge. penalty=l2, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.83      0.96      0.89       900
           1       0.93      0.90      0.91      1217
           2       0.99      0.85      0.92       298
           3       0.93      0.98      0.95       839
           4       0.93      0.94      0.93      1340
           5       0.98      0.95      0.96      1425
           6       1.00      0.90      0.95       511
           7       0.92      0.65      0.76       121
           8       0.96      0.97      0.96      1327
           9       0.98      0.95      0.97       192

    accuracy                           0.94      8170
   macro avg       0.94      0.91      0.92      8170
weighted avg       0.94      0.94      0.94      8170

CONFUSION MATRIX ----------------------
[[ 863   17    1    7    4    2    1    0    5    0]
 [  77 1095    0   11   15    5    0    0   12    2]
 [   3   29  254    1    3    0    0    3    5    0]
 [   0    3    0  821    7    4    0    0    4    0]
 [  13   19    0   24 1254   12    0    1   17    0]
 [  23    8    2   13   12 1356    1    1    8    1]
 [  30    3    0    1    9    0  461    0    7    0]
 [   6    0    0    3   32    0    0   79    1    0]
 [  20    3    0    5    7    8    0    2 1281    1]
 [   6    1    0    1    0    0    0    0    1  183]]
ACCURACY ----------------------
0.935985312117503
================================================

loss=hinge. penalty=elasticnet, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.92      0.90      0.91       900
           1       0.85      0.97      0.91      1217
           2       0.97      0.83      0.90       298
           3       0.97      0.96      0.97       839
           4       0.94      0.91      0.93      1340
           5       0.94      0.96      0.95      1425
           6       1.00      0.90      0.95       511
           7       0.82      0.65      0.73       121
           8       0.96      0.94      0.95      1327
           9       0.89      0.96      0.92       192

    accuracy                           0.93      8170
   macro avg       0.93      0.90      0.91      8170
weighted avg       0.93      0.93      0.93      8170

CONFUSION MATRIX ----------------------
[[ 811   68    2    2    6    5    0    0    6    0]
 [  18 1176    0    1    4    6    0    0    9    3]
 [   1   38  248    0    2    0    0    6    3    0]
 [   1    7    1  809    9    4    0    2    4    2]
 [   2   52    0   12 1221   31    0    2    7   13]
 [   7   25    4    2    8 1362    0    1   12    4]
 [  24    5    0    4    7    0  461    0   10    0]
 [   4    0    1    1   36    0    0   79    0    0]
 [  14    5    0    2    3   42    0    6 1254    1]
 [   4    1    0    0    2    0    0    0    1  184]]
ACCURACY ----------------------
0.9308445532435741
================================================

loss=hinge. penalty=elasticnet, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.86      0.96      0.91       900
           1       0.91      0.95      0.93      1217
           2       0.98      0.86      0.92       298
           3       0.95      0.98      0.96       839
           4       0.92      0.95      0.93      1340
           5       0.99      0.95      0.97      1425
           6       0.99      0.90      0.94       511
           7       0.81      0.64      0.72       121
           8       0.98      0.94      0.96      1327
           9       1.00      0.92      0.96       192

    accuracy                           0.94      8170
   macro avg       0.94      0.90      0.92      8170
weighted avg       0.94      0.94      0.94      8170

CONFUSION MATRIX ----------------------
[[ 865   23    1    2    5    2    1    0    1    0]
 [  40 1151    0    7   10    4    0    0    5    0]
 [   3   28  256    0    3    0    0    4    4    0]
 [   1    5    0  819    7    2    0    1    4    0]
 [   7   31    0   19 1270    4    0    4    5    0]
 [  22   17    1   10   16 1349    2    2    6    0]
 [  33    7    0    1    6    0  458    0    6    0]
 [   5    0    3    1   34    0    0   78    0    0]
 [  24    6    0    4   26    7    0    7 1253    0]
 [   8    3    0    3    1    0    0    0    1  176]]
ACCURACY ----------------------
0.9394124847001224
================================================

loss=perceptron. penalty=l2, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.80      0.95      0.87       900
           1       0.87      0.95      0.91      1217
           2       0.99      0.82      0.90       298
           3       0.97      0.95      0.96       839
           4       0.91      0.93      0.92      1340
           5       0.97      0.95      0.96      1425
           6       0.99      0.87      0.93       511
           7       0.66      0.73      0.69       121
           8       0.99      0.88      0.93      1327
           9       0.99      0.94      0.96       192

    accuracy                           0.92      8170
   macro avg       0.91      0.90      0.90      8170
weighted avg       0.93      0.92      0.92      8170

CONFUSION MATRIX ----------------------
[[ 857   36    2    0    1    2    1    0    0    1]
 [  40 1162    0    3    6    4    0    0    2    0]
 [   4   38  244    0    3    0    0    8    1    0]
 [  10   14    0  798    8    2    0    5    1    1]
 [  24   40    0   11 1242   12    0   11    0    0]
 [  27   20    0    1   15 1352    1    6    3    0]
 [  42   11    0    3    8    0  446    0    1    0]
 [   6    1    0    0   26    0    0   88    0    0]
 [  56   13    0    4   48   22    1   16 1167    0]
 [   8    2    0    0    1    0    0    0    1  180]]
ACCURACY ----------------------
0.9223990208078335
================================================

loss=perceptron. penalty=l2, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.88      0.95      0.91       900
           1       0.91      0.93      0.92      1217
           2       0.98      0.84      0.91       298
           3       0.99      0.95      0.97       839
           4       0.89      0.96      0.93      1340
           5       0.96      0.95      0.96      1425
           6       1.00      0.90      0.95       511
           7       0.87      0.64      0.73       121
           8       0.96      0.96      0.96      1327
           9       0.99      0.94      0.97       192

    accuracy                           0.94      8170
   macro avg       0.94      0.90      0.92      8170
weighted avg       0.94      0.94      0.94      8170

CONFUSION MATRIX ----------------------
[[ 852   28    3    0    8    4    0    0    5    0]
 [  30 1135    0    1   31    6    0    0   14    0]
 [   1   27  251    0   11    0    0    2    6    0]
 [   6    5    0  796   22    3    0    1    5    1]
 [   7   20    0    4 1284   18    0    1    6    0]
 [  15   19    1    1   22 1359    0    1    7    0]
 [  32    4    0    0    8    0  459    0    8    0]
 [   4    1    0    0   39    0    0   77    0    0]
 [  20    3    0    1    7   19    0    7 1270    0]
 [   6    1    0    0    3    0    0    0    1  181]]
ACCURACY ----------------------
0.9380660954712362
================================================

loss=perceptron. penalty=elasticnet, max_iteration=500

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.89      0.93      0.91       900
           1       0.86      0.96      0.91      1217
           2       0.99      0.80      0.88       298
           3       0.99      0.96      0.97       839
           4       0.90      0.94      0.92      1340
           5       0.95      0.95      0.95      1425
           6       1.00      0.86      0.92       511
           7       0.87      0.56      0.68       121
           8       0.96      0.94      0.95      1327
           9       0.96      0.95      0.96       192

    accuracy                           0.93      8170
   macro avg       0.94      0.89      0.91      8170
weighted avg       0.93      0.93      0.93      8170

CONFUSION MATRIX ----------------------
[[ 836   49    2    0    6    4    0    0    3    0]
 [  25 1167    0    1    8    6    0    0    9    1]
 [   2   41  238    0    9    0    0    4    4    0]
 [   3    8    0  805   13    3    0    0    5    2]
 [   4   40    0    6 1253   24    0    1    9    3]
 [  11   30    0    1   17 1357    0    1    8    0]
 [  27   13    0    0   24    0  439    0    8    0]
 [   5    2    1    0   44    0    0   68    1    0]
 [  19    4    0    2   10   32    1    4 1254    1]
 [   5    1    0    0    2    0    0    0    1  183]]
ACCURACY ----------------------
0.9302325581395349
================================================

loss=perceptron. penalty=elasticnet, max_iteration=1000

REPORT ----------------------
              precision    recall  f1-score   support

           0       0.84      0.96      0.90       900
           1       0.93      0.92      0.92      1217
           2       1.00      0.85      0.92       298
           3       0.99      0.95      0.97       839
           4       0.90      0.94      0.92      1340
           5       0.95      0.95      0.95      1425
           6       1.00      0.89      0.94       511
           7       0.76      0.64      0.70       121
           8       0.98      0.93      0.95      1327
           9       0.84      0.96      0.90       192

    accuracy                           0.93      8170
   macro avg       0.92      0.90      0.91      8170
weighted avg       0.93      0.93      0.93      8170

CONFUSION MATRIX ----------------------
[[ 867   18    0    0    9    4    0    0    1    1]
 [  59 1118    0    1   24    5    0    0    6    4]
 [   5   27  254    0    6    0    0    3    3    0]
 [   4    6    0  793   18    6    0    6    4    2]
 [   5   14    0    3 1266   27    0    3    4   18]
 [  20   15    0    1   15 1359    1    3    6    5]
 [  37    5    0    0    8    0  455    0    6    0]
 [   5    0    1    0   37    0    0   78    0    0]
 [  23    5    0    2   20   33    0    9 1231    4]
 [   6    0    0    0    0    0    0    0    1  185]]
ACCURACY ----------------------
0.9309669522643819
================================================
